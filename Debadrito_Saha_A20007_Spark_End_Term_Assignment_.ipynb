{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Debadrito_Saha_A20007_Spark_End_Term_Assignment_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZbgI9NZcEsM"
      },
      "source": [
        "# Prediction of Stroke Probabibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wspzfgZoEIP0"
      },
      "source": [
        "# Install Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbGuxmEWq0Zi"
      },
      "source": [
        "!apt-get update > /dev/null\r\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNRINuj7gEov"
      },
      "source": [
        "!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpyTkcJ-gFeI"
      },
      "source": [
        "!tar xf spark-3.0.1-bin-hadoop3.2.tgz\r\n",
        "!pip install -q findspark"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CilJyr64gFof"
      },
      "source": [
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myFMijMegFr2"
      },
      "source": [
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\""
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRLoMo5BgFvc"
      },
      "source": [
        "import findspark\r\n",
        "findspark.init()\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "BCctehvCgFzA",
        "outputId": "0661eeef-b380-45fc-9ac1-ed6441e7a8cb"
      },
      "source": [
        "sc = spark.sparkContext\r\n",
        "sc"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://46e8c0f5d85a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDEmvh_pEW0L"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnbpcCV3emeg"
      },
      "source": [
        "Data is available at : https://drive.google.com/drive/folders/1AbFCiys28K_xe4UjK9CzIVRqf2ynth9B?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I35qTTOsmcd"
      },
      "source": [
        "Steps to Read Data:-\r\n",
        "\r\n",
        "1. Download Data (csv file) from the above link\r\n",
        "2. Upload the csv file in your google drive\r\n",
        "3. Mount your drive in colab and get the path of the csv file from the drive\r\n",
        "4. Execute below code, after pasting the path inside quotes, to read the file in colab\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdTpklFXrNIO"
      },
      "source": [
        "train = spark.read.csv('/content/drive/MyDrive/Praxis/Course-Foundations of Data Science/Exams/Healthcare_Dataset.csv', inferSchema=True,header=True)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9VO-tjZrbIz",
        "outputId": "ef19e127-be72-4e77-8552-25d34ce437db"
      },
      "source": [
        "train.printSchema()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- age: double (nullable = true)\n",
            " |-- hypertension: integer (nullable = true)\n",
            " |-- heart_disease: integer (nullable = true)\n",
            " |-- ever_married: string (nullable = true)\n",
            " |-- work_type: string (nullable = true)\n",
            " |-- Residence_type: string (nullable = true)\n",
            " |-- avg_glucose_level: double (nullable = true)\n",
            " |-- bmi: string (nullable = true)\n",
            " |-- smoking_status: string (nullable = true)\n",
            " |-- stroke: integer (nullable = true)\n",
            " |-- _c12: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hBNZhdTEcxK"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9NntUUuJw8z"
      },
      "source": [
        "# Converting data-type of feature \"bmi\" from string to double\r\n",
        "\r\n",
        "train=train.withColumn(\"bmi\",train[\"bmi\"].cast(\"double\"))"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkpZSPshgxs8",
        "outputId": "f1a23a8c-7e72-4153-bd18-4e36eea88e81"
      },
      "source": [
        "train.groupBy('stroke').count().show()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|stroke|count|\n",
            "+------+-----+\n",
            "|     1|  249|\n",
            "|     0| 4861|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6JMqnTYQT8F"
      },
      "source": [
        "OBSERVATION :\r\n",
        "As can be seen from this observation. This is an Imbalanced dataset, where the number of observations belonging to one class is significantly lower than those belonging to the other classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LGBAFk5gyGW"
      },
      "source": [
        "# create DataFrame as a temporary view\r\n",
        "\r\n",
        "train.createOrReplaceTempView('table')"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnJdQJ3FgyYH",
        "outputId": "c7b6c6bf-3725-49ff-dde0-00bbb80c560e"
      },
      "source": [
        "spark.sql(\"SELECT work_type, count(work_type) as work_type_count FROM table WHERE stroke == 1 GROUP BY work_type \\\r\n",
        "ORDER BY work_type_count DESC\").show()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+---------------+\n",
            "|    work_type|work_type_count|\n",
            "+-------------+---------------+\n",
            "|      Private|            149|\n",
            "|Self-employed|             65|\n",
            "|     Govt_job|             33|\n",
            "|     children|              2|\n",
            "+-------------+---------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bpRy1ZzQXLk"
      },
      "source": [
        "OBSERVATION :\r\n",
        "Private occupation is the most dangerous work type in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2VVz4xjgylI",
        "outputId": "10928438-2d68-4519-e4cb-9ea780a2af7d"
      },
      "source": [
        "spark.sql(\"SELECT gender, count(gender) as count_gender, count(gender)*100/sum(count(gender)) over() \\\r\n",
        " as percent  FROM table GROUP BY gender\").show()\r\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+------------+--------------------+\n",
            "|gender|count_gender|             percent|\n",
            "+------+------------+--------------------+\n",
            "|Female|        2994|  58.590998043052835|\n",
            "| Other|           1|0.019569471624266144|\n",
            "|  Male|        2115|    41.3894324853229|\n",
            "+------+------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDf9gmB1RCQk"
      },
      "source": [
        "OBSERVATION :\r\n",
        "59% of all people are Female and only 41% are Male that participated in stroke research."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXorVtn-gyok",
        "outputId": "d7556dbf-af5a-4ce0-f642-9f6daf47ac22"
      },
      "source": [
        "spark.sql(\"SELECT gender, count(gender), (COUNT(gender) * 100.0) /(SELECT count(gender) FROM table WHERE gender == 'Male') as \\\r\n",
        "percentage FROM table WHERE stroke = '1' and gender = 'Male' GROUP BY gender\").show()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------+----------------+\n",
            "|gender|count(gender)|      percentage|\n",
            "+------+-------------+----------------+\n",
            "|  Male|          108|5.10638297872340|\n",
            "+------+-------------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiM3-1asRLc2"
      },
      "source": [
        " OBSERVATION :\r\n",
        " 5% Male have had a stroke."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQk5Lnaegy4X",
        "outputId": "f22c4a90-a9d3-41e9-8cd8-d1cadde32f56"
      },
      "source": [
        "spark.sql(\"SELECT gender, count(gender), (COUNT(gender) * 100.0) /(SELECT count(gender) FROM table WHERE gender == 'Female') as \\\r\n",
        "percentage FROM table WHERE stroke = '1' and gender = 'Female' GROUP BY gender\").show()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------+----------------+\n",
            "|gender|count(gender)|      percentage|\n",
            "+------+-------------+----------------+\n",
            "|Female|          141|4.70941883767535|\n",
            "+------+-------------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJHaXXYsRW2F"
      },
      "source": [
        "OBSERVATION : 4.7% Female have had a stroke."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCzLBuVCgy7W",
        "outputId": "b4425fe5-2321-4a45-f6ad-2f83c1cb47f4"
      },
      "source": [
        "# RISK BY AGE\r\n",
        "\r\n",
        "spark.sql(\"SELECT age, count(age) as age_count FROM table WHERE stroke == 1 GROUP BY age ORDER BY age_count DESC\").show()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+---------+\n",
            "| age|age_count|\n",
            "+----+---------+\n",
            "|78.0|       21|\n",
            "|79.0|       17|\n",
            "|80.0|       17|\n",
            "|81.0|       14|\n",
            "|57.0|       11|\n",
            "|76.0|       10|\n",
            "|68.0|        9|\n",
            "|74.0|        9|\n",
            "|63.0|        9|\n",
            "|82.0|        9|\n",
            "|59.0|        8|\n",
            "|77.0|        8|\n",
            "|71.0|        7|\n",
            "|58.0|        7|\n",
            "|69.0|        6|\n",
            "|70.0|        6|\n",
            "|72.0|        6|\n",
            "|61.0|        6|\n",
            "|54.0|        6|\n",
            "|75.0|        6|\n",
            "+----+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpGVreKR3a7s",
        "outputId": "9dd9148b-af85-403f-eee8-06375579b59b"
      },
      "source": [
        "train.filter((train['stroke'] == 1) & (train['age'] > '50')).count()\r\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "226"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5HhzokcR9eY"
      },
      "source": [
        "OBSERVATION: \r\n",
        "using filter operation to calculate the number of stroke cases for people after 50 years.\r\n",
        "\r\n",
        "As we can see Age is an important risk factor for developing a stroke."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuSSlHB2FA6K"
      },
      "source": [
        "# Dealing with Null Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YO6cZP1E3dh",
        "outputId": "d95c24b5-bfae-4309-dcad-2530a155b4dd"
      },
      "source": [
        "#checking Null values\r\n",
        "\r\n",
        "train.toPandas().isnull().sum()\r\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                      0\n",
              "gender                  0\n",
              "age                     0\n",
              "hypertension            0\n",
              "heart_disease           0\n",
              "ever_married            0\n",
              "work_type               0\n",
              "Residence_type          0\n",
              "avg_glucose_level       0\n",
              "bmi                   201\n",
              "smoking_status          0\n",
              "stroke                  0\n",
              "_c12                 5110\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bi2UqkNGVty"
      },
      "source": [
        "# fill in miss values with mean for feature \"bmi\"\r\n",
        "\r\n",
        "from pyspark.sql.functions import mean\r\n",
        "mean = train.select(mean(train['bmi'])).collect()\r\n",
        "mean_bmi = mean[0][0]\r\n",
        "train_f = train.na.fill(mean_bmi,['bmi'])"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0dQxuwPM4_E",
        "outputId": "82a6d043-894f-4b54-933e-653199977c70"
      },
      "source": [
        "# Recheck if any further null values are present\r\n",
        "\r\n",
        "train_f.toPandas().isnull().sum()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                      0\n",
              "gender                  0\n",
              "age                     0\n",
              "hypertension            0\n",
              "heart_disease           0\n",
              "ever_married            0\n",
              "work_type               0\n",
              "Residence_type          0\n",
              "avg_glucose_level       0\n",
              "bmi                     0\n",
              "smoking_status          0\n",
              "stroke                  0\n",
              "_c12                 5110\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdUNDmw89DU9",
        "outputId": "126dade1-ee53-454c-f28b-dd61e34147a0"
      },
      "source": [
        "train_f.describe().show()"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------------+------+------------------+------------------+-------------------+------------+---------+--------------+------------------+-----------------+--------------+-------------------+----+\n",
            "|summary|               id|gender|               age|      hypertension|      heart_disease|ever_married|work_type|Residence_type| avg_glucose_level|              bmi|smoking_status|             stroke|_c12|\n",
            "+-------+-----------------+------+------------------+------------------+-------------------+------------+---------+--------------+------------------+-----------------+--------------+-------------------+----+\n",
            "|  count|             5110|  5110|              5110|              5110|               5110|        5110|     5110|          5110|              5110|             5110|          5110|               5110|   0|\n",
            "|   mean|36517.82935420744|  null|43.226614481409015|0.0974559686888454|0.05401174168297456|        null|     null|          null|106.14767710371804|28.89323691179472|          null| 0.0487279843444227|null|\n",
            "| stddev|21161.72162482715|  null| 22.61264672311348| 0.296606674233791|0.22606298750336554|        null|     null|          null| 45.28356015058193|7.698017826857079|          null|0.21531985698023753|null|\n",
            "|    min|               67|Female|              0.08|                 0|                  0|          No| Govt_job|         Rural|             55.12|             10.3|       Unknown|                  0|null|\n",
            "|    max|            72940| Other|              82.0|                 1|                  1|         Yes| children|         Urban|            271.74|             97.6|        smokes|                  1|null|\n",
            "+-------+-----------------+------+------------------+------------------+-------------------+------------+---------+--------------+------------------+-----------------+--------------+-------------------+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du2qklEmFKIq"
      },
      "source": [
        "# One Hot Encoding (Dealing with Categorical Variables)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNxSbBax3a1_"
      },
      "source": [
        "from pyspark.ml.feature import (VectorAssembler,OneHotEncoder,\r\n",
        "                                StringIndexer)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1reLB7VX3a0P"
      },
      "source": [
        "# indexing all categorical columns in the dataset\r\n",
        "from pyspark.ml.feature import StringIndexer\r\n",
        "indexer1 = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\")\r\n",
        "indexer2 = StringIndexer(inputCol=\"ever_married\", outputCol=\"ever_marriedIndex\")\r\n",
        "indexer3 = StringIndexer(inputCol=\"work_type\", outputCol=\"work_typeIndex\")\r\n",
        "indexer4 = StringIndexer(inputCol=\"Residence_type\", outputCol=\"Residence_typeIndex\")\r\n",
        "indexer5 = StringIndexer(inputCol=\"smoking_status\", outputCol=\"smoking_statusIndex\")"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11DyqFjJ3azC"
      },
      "source": [
        "# Doing one hot encoding of indexed data\r\n",
        "from pyspark.ml.feature import OneHotEncoder\r\n",
        "encoder = OneHotEncoder(inputCols=[\"genderIndex\",\"ever_marriedIndex\",\"work_typeIndex\",\"Residence_typeIndex\",\"smoking_statusIndex\"],\r\n",
        "                                 outputCols=[\"genderVec\",\"ever_marriedVec\",\"work_typeVec\",\"Residence_typeVec\",\"smoking_statusVec\"])"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHjkGz_0Cunq"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\r\n",
        "assembler = VectorAssembler(inputCols=['genderVec',\r\n",
        " 'age',\r\n",
        " 'hypertension',\r\n",
        " 'heart_disease',\r\n",
        " 'ever_marriedVec',\r\n",
        " 'work_typeVec',\r\n",
        " 'Residence_typeVec',\r\n",
        " 'avg_glucose_level',\r\n",
        " 'bmi',\r\n",
        " 'smoking_statusVec'],outputCol='features')"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8aM8TVAGx3E"
      },
      "source": [
        "# Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoiLSmvCGtbS"
      },
      "source": [
        "# splitting training and validation data\r\n",
        "\r\n",
        "train_data,val_data = train_f.randomSplit([0.7,0.3],seed=100)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvsDrs15ImZ_"
      },
      "source": [
        "# DECISION TREE CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZgF37p1IjKb"
      },
      "source": [
        "#Importing Decision Tree  Classifiers\r\n",
        "\r\n",
        "from pyspark.ml.classification import DecisionTreeClassifier"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUgMJ7H5Oc5v"
      },
      "source": [
        "dtc = DecisionTreeClassifier(labelCol='stroke',featuresCol='features')"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t7PWjvfMtRP"
      },
      "source": [
        "# Creating Pipeline\r\n",
        "\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "\r\n",
        "pipeline_1 = Pipeline(stages=[indexer1, indexer2, indexer3, indexer4, indexer5, encoder, assembler,dtc])"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k6BRnPKnbbU"
      },
      "source": [
        "# Training Model\r\n",
        "\r\n",
        "model = pipeline_1.fit(train_data)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkiDx3xgI8wC"
      },
      "source": [
        "Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyKUXEUaF6Dr"
      },
      "source": [
        "dtc_predictions = model.transform(val_data)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODY2sNUCJA5O"
      },
      "source": [
        "# Decision Tree Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHDAnlbDJFZl"
      },
      "source": [
        "Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPByI9lVnTJH",
        "outputId": "cb2225c5-48bc-45bd-efac-0a7831fa8676"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\n",
        "\r\n",
        "# Select (prediction, true label) and compute test error\r\n",
        "\r\n",
        "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"stroke\", predictionCol=\"prediction\", metricName=\"accuracy\")\r\n",
        "\r\n",
        "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\r\n",
        "\r\n",
        "print('A Decision Tree algorithm had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A Decision Tree algorithm had an accuracy of: 95.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkLadUeUJXlK"
      },
      "source": [
        "AUC-ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OrGVY8wnTF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca878c24-329d-4125-db23-bac08e815ef0"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\r\n",
        "\r\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='stroke')\r\n",
        "\r\n",
        "# area under ROC curve\r\n",
        "\r\n",
        "auroc = evaluator.evaluate(dtc_predictions, {evaluator.metricName: \"areaUnderROC\"})\r\n",
        "print(\"Area under ROC Curve: {:.4f}\".format(auroc))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under ROC Curve: 0.3578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8es8Wd_pFYhr"
      },
      "source": [
        "# LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qks5jAFPCujR"
      },
      "source": [
        "#Importing Logistic Regression \r\n",
        "\r\n",
        "from pyspark.ml.classification import LogisticRegression\r\n"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA1mGgTkFdrk"
      },
      "source": [
        "# Logistic Regression\r\n",
        "\r\n",
        "lr = LogisticRegression(labelCol='stroke',featuresCol='features',maxIter=5)"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XerGqQq9CugG"
      },
      "source": [
        "# Creating Pipeline\r\n",
        "\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "pipeline_2 = Pipeline(stages=[indexer1, indexer2, indexer3, indexer4, indexer5, encoder, assembler,lr])"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPNRT9dJCucv"
      },
      "source": [
        "# training model pipeline with data\r\n",
        "\r\n",
        "model = pipeline_2.fit(train_data)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTgDxrJwG9NR"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-wZetvjgy-I"
      },
      "source": [
        "lr_predictions=model.transform(val_data)\r\n"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avx3BlJAHZhn"
      },
      "source": [
        "# Logistic Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwVwfZFdIC-B"
      },
      "source": [
        "Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDo7EXEJgF6O",
        "outputId": "fb164f68-b6ec-4e23-ac65-a8715a9a92be"
      },
      "source": [
        "# Accuracy Score\r\n",
        "\r\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\n",
        "\r\n",
        "# Select (prediction, true label) and compute test error\r\n",
        "\r\n",
        "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"stroke\", predictionCol=\"prediction\", metricName=\"accuracy\")\r\n",
        "lr_acc=acc_evaluator.evaluate(lr_predictions)\r\n",
        "\r\n",
        "print('A Logistic Regression algorithm had an accuracy of: {0:2.2f}%'.format(lr_acc*100))\r\n"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A Logistic Regression algorithm had an accuracy of: 95.16%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrQtX6QeIF4d"
      },
      "source": [
        "AUC-ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3wMW9zeHkRy",
        "outputId": "89f72fd9-fa5c-4579-8ef1-ac098089e17b"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\r\n",
        "\r\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='stroke')\r\n",
        "\r\n",
        "# area under ROC curve\r\n",
        "\r\n",
        "auroc = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"areaUnderROC\"})\r\n",
        "print(\"Area under ROC Curve: {:.4f}\".format(auroc))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under ROC Curve: 0.8009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK0KXfi6-TBO"
      },
      "source": [
        "# Random Forest Classifier (Ensemble)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91eRr5T7-PWP"
      },
      "source": [
        "#Importing Random Forest\r\n",
        "\r\n",
        "from pyspark.ml.classification import RandomForestClassifier\r\n"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Zh77az-z4q"
      },
      "source": [
        "# RF\r\n",
        "\r\n",
        "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'stroke')"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-QjVjWS-4qi"
      },
      "source": [
        "#Creating Pipeline\r\n",
        "\r\n",
        "pipeline_3 = Pipeline(stages=[indexer1, indexer2, indexer3, indexer4, indexer5, encoder, assembler,rf])\r\n",
        "\r\n"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDnEzrn-_3iK"
      },
      "source": [
        "# Training\r\n",
        "\r\n",
        "model = pipeline_3.fit(train_data)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-IfAjOaBdIN"
      },
      "source": [
        "Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJTWcYOW-PZx"
      },
      "source": [
        "\r\n",
        "rf_predictions=model.transform(val_data)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1d69UuV__-v"
      },
      "source": [
        "# RF_Model_Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BXvxpAbAGHZ"
      },
      "source": [
        "Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sn0tUFz-Pdc",
        "outputId": "2800202f-f5e0-421f-c9fd-db022a0bc252"
      },
      "source": [
        "#Accuracy Score\r\n",
        "\r\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\n",
        "\r\n",
        "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"stroke\", predictionCol=\"prediction\", metricName=\"accuracy\")\r\n",
        "\r\n",
        "rf_acc=acc_evaluator.evaluate(rf_predictions)\r\n",
        "\r\n",
        "print('A Random Forest algorithm had an accuracy of: {0:2.2f}%'.format(rf_acc*100))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A Random Forest algorithm had an accuracy of: 95.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYp94LDlAbR6"
      },
      "source": [
        "AUC-ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3QKfXun-PgO",
        "outputId": "6738c519-a114-4238-dce9-4131e62b2d8d"
      },
      "source": [
        "#Area under curve\r\n",
        "\r\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='stroke')\r\n",
        "\r\n",
        "auroc = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"areaUnderROC\"})\r\n",
        "\r\n",
        "print(\"Area under ROC Curve: {:.4f}\".format(auroc))\r\n"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under ROC Curve: 0.7826\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}